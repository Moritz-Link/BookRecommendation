{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt \n",
    "#import seaborn as sns \n",
    "from torch.nn import Conv1d, MaxPool1d, Linear, Dropout, BCEWithLogitsLoss\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import  torch_geometric\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip'\n",
    "with urlopen(url) as zurl:\n",
    "    with ZipFile(BytesIO(zurl.read())) as zfile:\n",
    "        zfile.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_20688\\3022968751.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(p+'BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines=\"skip\")\n"
     ]
    }
   ],
   "source": [
    "p = \"\"\n",
    "ratings = pd.read_csv(p+'BX-Book-Ratings.csv', sep=';', encoding='latin-1')\n",
    "users = pd.read_csv(p+'BX-Users.csv', sep=';', encoding='latin-1')\n",
    "books = pd.read_csv(p+'BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing -> Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mapping_user: \n",
      "   user_id  user_id_mapped\n",
      "0   276747               0\n",
      "1   276751               1\n",
      "2   276754               2\n",
      "3   276762               3\n",
      "4   276772               4\n",
      "====================\n",
      "df_mapping_item: \n",
      "      isbn_id  isbn_id_mapped\n",
      "0  0060517794               0\n",
      "1  0671537458               1\n",
      "2  0679776818               2\n",
      "3  3596218098               3\n",
      "4  0684867621               4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_id_mapped</th>\n",
       "      <th>isbn_id</th>\n",
       "      <th>isbn_id_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "      <td>276747</td>\n",
       "      <td>0</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276747</td>\n",
       "      <td>0671537458</td>\n",
       "      <td>9</td>\n",
       "      <td>276747</td>\n",
       "      <td>0</td>\n",
       "      <td>0671537458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276747</td>\n",
       "      <td>0679776818</td>\n",
       "      <td>8</td>\n",
       "      <td>276747</td>\n",
       "      <td>0</td>\n",
       "      <td>0679776818</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276751</td>\n",
       "      <td>3596218098</td>\n",
       "      <td>8</td>\n",
       "      <td>276751</td>\n",
       "      <td>1</td>\n",
       "      <td>3596218098</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276754</td>\n",
       "      <td>0684867621</td>\n",
       "      <td>8</td>\n",
       "      <td>276754</td>\n",
       "      <td>2</td>\n",
       "      <td>0684867621</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating  user_id  user_id_mapped     isbn_id  \\\n",
       "0   276747  0060517794            9   276747               0  0060517794   \n",
       "1   276747  0671537458            9   276747               0  0671537458   \n",
       "2   276747  0679776818            8   276747               0  0679776818   \n",
       "3   276751  3596218098            8   276751               1  3596218098   \n",
       "4   276754  0684867621            8   276754               2  0684867621   \n",
       "\n",
       "   isbn_id_mapped  \n",
       "0               0  \n",
       "1               1  \n",
       "2               2  \n",
       "3               3  \n",
       "4               4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_filtered = ratings.loc[ratings[\"Book-Rating\"] >= 8]\n",
    "#sns.countplot(x =ratings_filtered[\"Book-Rating\"])\n",
    "ratings_filtered = ratings_filtered.loc[ratings_filtered['ISBN'].isin(books['ISBN'].unique()) & ratings_filtered['User-ID'].isin(users['User-ID'].unique())]\n",
    "\n",
    "# Mappings\n",
    "mapping_user = { user_id: index for index, user_id in enumerate(ratings_filtered[\"User-ID\"].unique())}\n",
    "mapping_item = { isbn_id: index for index, isbn_id in enumerate(ratings_filtered[\"ISBN\"].unique())}\n",
    "\n",
    "df_mapping_user = pd.DataFrame()\n",
    "df_mapping_user[\"user_id\"] = mapping_user.keys()\n",
    "df_mapping_user[\"user_id_mapped\"] = mapping_user.values()\n",
    "\n",
    "df_mapping_item = pd.DataFrame()\n",
    "df_mapping_item[\"isbn_id\"] = mapping_item.keys()\n",
    "df_mapping_item[\"isbn_id_mapped\"] = mapping_item.values()\n",
    "\n",
    "print(f'df_mapping_user: ')\n",
    "print(f'{df_mapping_user.head()}')\n",
    "print(\"==\"*10)\n",
    "print(f'df_mapping_item: ')\n",
    "print(f'{df_mapping_item.head()}')\n",
    "\n",
    "ratings_filtered_m = ratings_filtered.merge(df_mapping_user, left_on = \"User-ID\", right_on=\"user_id\", how = \"left\")\n",
    "ratings_filtered_m = ratings_filtered_m.merge(df_mapping_item, left_on = \"ISBN\", right_on=\"isbn_id\", how = \"left\")\n",
    "ratings_filtered_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223807 entries, 0 to 223806\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   User-ID         223807 non-null  int64 \n",
      " 1   ISBN            223807 non-null  object\n",
      " 2   Book-Rating     223807 non-null  int64 \n",
      " 3   user_id         223807 non-null  int64 \n",
      " 4   user_id_mapped  223807 non-null  int64 \n",
      " 5   isbn_id         223807 non-null  object\n",
      " 6   isbn_id_mapped  223807 non-null  int64 \n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings_filtered_m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_id_mapped</th>\n",
       "      <th>isbn_id_mapped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9971400162</th>\n",
       "      <td>114865.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>114865.0</td>\n",
       "      <td>19984.0</td>\n",
       "      <td>57432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001821326</th>\n",
       "      <td>201017.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>201017.0</td>\n",
       "      <td>34204.0</td>\n",
       "      <td>80786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001374869</th>\n",
       "      <td>10067.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10067.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>6861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0001I1KOG</th>\n",
       "      <td>148258.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>148258.0</td>\n",
       "      <td>25555.0</td>\n",
       "      <td>66369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001360469</th>\n",
       "      <td>10067.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10067.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>6860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0679803726</th>\n",
       "      <td>93047.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>93047.0</td>\n",
       "      <td>16189.0</td>\n",
       "      <td>45604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>075350426X</th>\n",
       "      <td>203456.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>203456.0</td>\n",
       "      <td>34585.0</td>\n",
       "      <td>81276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0753504545</th>\n",
       "      <td>236727.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>236727.0</td>\n",
       "      <td>40280.0</td>\n",
       "      <td>89131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0753505045</th>\n",
       "      <td>183316.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>183316.0</td>\n",
       "      <td>31357.0</td>\n",
       "      <td>76440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000913154</th>\n",
       "      <td>171118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>171118.0</td>\n",
       "      <td>29332.0</td>\n",
       "      <td>72790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98417 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             User-ID  Book-Rating   user_id  user_id_mapped  isbn_id_mapped\n",
       "isbn_id                                                                    \n",
       "9971400162  114865.0         10.0  114865.0         19984.0         57432.0\n",
       "0001821326  201017.0         10.0  201017.0         34204.0         80786.0\n",
       "0001374869   10067.0         10.0   10067.0          1999.0          6861.0\n",
       "B0001I1KOG  148258.0         10.0  148258.0         25555.0         66369.0\n",
       "0001360469   10067.0         10.0   10067.0          1999.0          6860.0\n",
       "...              ...          ...       ...             ...             ...\n",
       "0679803726   93047.0          8.0   93047.0         16189.0         45604.0\n",
       "075350426X  203456.0          8.0  203456.0         34585.0         81276.0\n",
       "0753504545  236727.0          8.0  236727.0         40280.0         89131.0\n",
       "0753505045  183316.0          8.0  183316.0         31357.0         76440.0\n",
       "0000913154  171118.0          8.0  171118.0         29332.0         72790.0\n",
       "\n",
       "[98417 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = ratings_filtered_m.groupby([\"isbn_id\"]).mean(numeric_only=True)\n",
    "grouped = grouped.sort_values(['Book-Rating'], ascending=False)\n",
    "grouped.to_csv(\"ISBNS_grouped.csv\")\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 47071, 47072, 47073],\n",
       "        [    0,     1,     2,  ..., 98416, 12023, 79963]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edge_index_user_to_isbn\n",
    "edge_index_user_to_isbn = ratings_filtered_m[[\"user_id_mapped\", \"isbn_id_mapped\"]]\n",
    "edge_index_user_to_isbn_user = torch.from_numpy(edge_index_user_to_isbn.user_id_mapped.values)\n",
    "edge_index_user_to_isbn_isbn =torch.from_numpy( edge_index_user_to_isbn.isbn_id_mapped.values)\n",
    "edge_index_user_to_isbn_user\n",
    "edge_index_user_to_isbn_isbn\n",
    "\n",
    "edge_index_user_to_isbn = torch.stack([edge_index_user_to_isbn_user, edge_index_user_to_isbn_isbn], dim=0)\n",
    "edge_index_user_to_isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98417\n",
      "98417\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98417 entries, 0 to 98416\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Year-Of-Publication  98417 non-null  object\n",
      " 1   Publisher            98415 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "--- Year-Of-Publication 166\n",
      "--- Publisher 8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_20688\\2122506642.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  book_x.replace({True:1, False:0}, inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbook_x[c]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m book_x \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(book_x, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPublisher\u001b[39m\u001b[38;5;124m\"\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublisher\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 22\u001b[0m \u001b[43mbook_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m book_x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear-Of-Publication\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m book_x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear-Of-Publication\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     26\u001b[0m display(book_x\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\morit\\Documents\\Python Scripts\\me2\\lib\\site-packages\\pandas\\core\\generic.py:8051\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   8048\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   8049\u001b[0m         to_replace, value \u001b[38;5;241m=\u001b[39m keys, values\n\u001b[1;32m-> 8051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_replace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregex\u001b[49m\n\u001b[0;32m   8053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   8055\u001b[0m     \u001b[38;5;66;03m# need a non-zero len on all axes\u001b[39;00m\n\u001b[0;32m   8056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[1;32mc:\\Users\\morit\\Documents\\Python Scripts\\me2\\lib\\site-packages\\pandas\\core\\generic.py:8099\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   8094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_replace) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[0;32m   8095\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   8096\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplacement lists must match in length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8097\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_replace)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8098\u001b[0m         )\n\u001b[1;32m-> 8099\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8100\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_replace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdest_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8102\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_replace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   8108\u001b[0m         is_re_compilable(regex)\n\u001b[0;32m   8109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_list_like(regex)\n\u001b[0;32m   8110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_dict_like(regex)\n\u001b[0;32m   8111\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\morit\\Documents\\Python Scripts\\me2\\lib\\site-packages\\pandas\\core\\internals\\base.py:278\u001b[0m, in \u001b[0;36mDataManager.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[0;32m    276\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 278\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplace_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdest_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m bm\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32mc:\\Users\\morit\\Documents\\Python Scripts\\me2\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\morit\\Documents\\Python Scripts\\me2\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1147\u001b[0m, in \u001b[0;36mBlock.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex, using_cow, already_warned)\u001b[0m\n\u001b[0;32m   1145\u001b[0m nbs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res_blk \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m-> 1147\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43mres_blk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_cow\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(converted) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m converted[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m res_blk\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[0;32m   1151\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1152\u001b[0m             \u001b[38;5;66;03m# GH#54710\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDowncasting behavior in `replace` is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1161\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1162\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\morit\\Documents\\Python Scripts\\me2\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:636\u001b[0m, in \u001b[0;36mBlock.convert\u001b[1;34m(self, copy, using_cow)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_cow:\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m--> 636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m]\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    639\u001b[0m     blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_and_operate(\n\u001b[0;32m    640\u001b[0m         Block\u001b[38;5;241m.\u001b[39mconvert, copy\u001b[38;5;241m=\u001b[39mcopy, using_cow\u001b[38;5;241m=\u001b[39musing_cow\n\u001b[0;32m    641\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\morit\\Documents\\Python Scripts\\me2\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "book_x = books[[\"ISBN\", \"Year-Of-Publication\", \"Publisher\"]]\n",
    "book_x = book_x[(book_x[\"ISBN\"].isin(list(ratings_filtered_m.isbn_id.unique())) )]\n",
    "#ratings_filtered_m.isbn_id.unique()\n",
    "\n",
    "print(len(book_x[\"ISBN\"].values))\n",
    "print(len(ratings_filtered_m.isbn_id.unique()))\n",
    "\n",
    "#df_mapping_item, left_on = \"ISBN\", right_on=\"isbn_id\", how = \"left\"\n",
    "book_x = book_x.merge(df_mapping_item,left_on =  \"ISBN\",right_on = \"isbn_id\", how= \"left\")\n",
    "book_x = book_x.sort_values(by=['isbn_id_mapped'])\n",
    "\n",
    "book_x = book_x.set_index('isbn_id_mapped')\n",
    "book_x = book_x[[\"Year-Of-Publication\", \"Publisher\"]]\n",
    "\n",
    "print(book_x.info())\n",
    "\n",
    "for c in [ \"Year-Of-Publication\", \"Publisher\"]:\n",
    "    \n",
    "    print(f'--- {c} {book_x[c].nunique()}')\n",
    "    \n",
    "book_x = pd.get_dummies(book_x, columns=[\"Publisher\"], prefix=[\"publisher\"])\n",
    "book_x.replace({True:1, False:0}, inplace=True)\n",
    "book_x[\"Year-Of-Publication\"]= book_x[\"Year-Of-Publication\"].astype(int)\n",
    "\n",
    "\n",
    "display(book_x.head(2))\n",
    "\n",
    "\n",
    "print(\"After Transformation\")\n",
    "print(book_x.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ node_id=[47074] },\n",
      "  isbn={\n",
      "    node_id=[98417],\n",
      "    x=[98417, 8751],\n",
      "  },\n",
      "  (user, review, isbn)={ edge_index=[2, 223807] },\n",
      "  (isbn, rev_review, user)={ edge_index=[2, 223807] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch_isbn = torch.tensor(book_x.values)\n",
    "torch_isbn.shape\n",
    "\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data[\"user\"].node_id = torch.from_numpy(ratings_filtered_m.user_id_mapped.unique())\n",
    "data[\"isbn\"].node_id =torch.from_numpy(ratings_filtered_m.isbn_id_mapped.unique())\n",
    "data[\"isbn\"].x = torch_isbn\n",
    "data[\"user\", \"review\", \"isbn\"].edge_index  = edge_index_user_to_isbn\n",
    "data = T.ToUndirected()(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation -> Random Splitter + LinkLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"user\", \"review\", \"isbn\"),\n",
    "    rev_edge_types=(\"isbn\", \"rev_review\", \"user\"), \n",
    ")\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Define seed edges:\n",
    "edge_label_index = train_data[\"user\", \"review\", \"isbn\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"review\", \"isbn\"].edge_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[5, 5],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"review\", \"isbn\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    \n",
    "     data=val_data,\n",
    "    num_neighbors=[5, 5],\n",
    "    #neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"review\", \"isbn\"), val_data[\"user\", \"review\", \"isbn\"].edge_label_index),\n",
    "    edge_label=val_data[\"user\", \"review\", \"isbn\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    \n",
    "     data=test_data,\n",
    "    num_neighbors=[5, 5],\n",
    "    #neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"review\", \"isbn\"), test_data[\"user\", \"review\", \"isbn\"].edge_label_index),\n",
    "    edge_label=test_data[\"user\", \"review\", \"isbn\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    )\n",
    "#test_loader = LinkNeighborLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1muser\u001b[0m={ node_id=[47074] },\n",
       "  \u001b[1misbn\u001b[0m={\n",
       "    node_id=[98417],\n",
       "    x=[98417, 8751]\n",
       "  },\n",
       "  \u001b[1m(user, review, isbn)\u001b[0m={\n",
       "    edge_index=[2, 125333],\n",
       "    edge_label=[53714],\n",
       "    edge_label_index=[2, 53714]\n",
       "  },\n",
       "  \u001b[1m(isbn, rev_review, user)\u001b[0m={ edge_index=[2, 125333] }\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    node_id=[2010],\n",
       "    n_id=[2010],\n",
       "    num_sampled_nodes=[3],\n",
       "  },\n",
       "  isbn={\n",
       "    node_id=[2514],\n",
       "    x=[2514, 8751],\n",
       "    n_id=[2514],\n",
       "    num_sampled_nodes=[3],\n",
       "  },\n",
       "  (user, review, isbn)={\n",
       "    edge_index=[2, 2638],\n",
       "    edge_label=[384],\n",
       "    edge_label_index=[2, 384],\n",
       "    e_id=[2638],\n",
       "    num_sampled_edges=[2],\n",
       "    input_id=[128],\n",
       "  },\n",
       "  (isbn, rev_review, user)={\n",
       "    edge_index=[2, 2601],\n",
       "    e_id=[2601],\n",
       "    num_sampled_edges=[2],\n",
       "  }\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_data = next(iter(train_loader))\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cpu'\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HeteroData.metadata of HeteroData(\n",
       "  user={ node_id=[47074] },\n",
       "  isbn={\n",
       "    node_id=[98417],\n",
       "    x=[98417, 8751],\n",
       "  },\n",
       "  (user, review, isbn)={ edge_index=[2, 223807] },\n",
       "  (isbn, rev_review, user)={ edge_index=[2, 223807] }\n",
       ")>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "    def forward(self, x, edge_index) :\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x \n",
    "    \n",
    "class Classifier(torch.nn.Module): \n",
    "    def forward(self, x_user, x_movie, edge_label_index) :\n",
    "        \n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
    "        \n",
    "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
    "    \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.movie_lin = torch.nn.Linear(8751, hidden_channels)\n",
    "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
    "        self.movie_emb = torch.nn.Embedding(data[\"isbn\"].num_nodes, hidden_channels)\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "        self.classifier = Classifier()\n",
    "        \n",
    "    def forward(self, data: HeteroData) :\n",
    "    \n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
    "          \"isbn\": self.movie_lin(data[\"isbn\"].x.float()) + self.movie_emb(data[\"isbn\"].node_id),\n",
    "        } \n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"isbn\"],\n",
    "            data[\"user\", \"review\", \"isbn\"].edge_label_index,\n",
    "        )\n",
    "        return pred\n",
    "    \n",
    "model = Model(hidden_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        sampled_data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(sampled_data)\n",
    "        ground_truth = sampled_data[\"user\", \"review\", \"isbn\"].edge_label\n",
    "        loss = criterion(pred, ground_truth)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "    #print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "    \n",
    "    for s_data in tqdm.tqdm(loader):\n",
    "        \n",
    "        s_data = s_data.to(device)\n",
    "        out = model(s_data)\n",
    "        y_pred.append(out)\n",
    "        ground_truth = s_data[\"user\", \"review\", \"isbn\"].edge_label\n",
    "        y_true.append(ground_truth)\n",
    "    auc = roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
    "    ap = average_precision_score(torch.cat(y_true), torch.cat(y_pred))\n",
    "\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/420 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [04:53<00:00,  1.43it/s]\n",
      "100%|██████████| 525/525 [02:30<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | Loss: 2.1353 | Val AUC: 0.5798 | Val AP: 0.3638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [05:11<00:00,  1.35it/s]\n",
      "100%|██████████| 420/420 [03:29<00:00,  2.01it/s]\n",
      "100%|██████████| 420/420 [03:17<00:00,  2.13it/s]\n",
      "100%|██████████| 420/420 [03:18<00:00,  2.12it/s]\n",
      "100%|██████████| 420/420 [03:17<00:00,  2.12it/s]\n",
      "100%|██████████| 525/525 [01:35<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Loss: 0.5514 | Val AUC: 0.7475 | Val AP: 0.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [04:05<00:00,  1.71it/s]\n",
      "100%|██████████| 420/420 [03:58<00:00,  1.76it/s]\n",
      "100%|██████████| 420/420 [05:21<00:00,  1.31it/s]\n",
      "100%|██████████| 420/420 [04:03<00:00,  1.73it/s]\n",
      "100%|██████████| 420/420 [03:16<00:00,  2.13it/s]\n",
      "100%|██████████| 525/525 [01:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.4598 | Val AUC: 0.8204 | Val AP: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [03:18<00:00,  2.11it/s]\n",
      "100%|██████████| 420/420 [03:17<00:00,  2.13it/s]\n",
      "100%|██████████| 420/420 [03:17<00:00,  2.13it/s]\n",
      "100%|██████████| 420/420 [03:19<00:00,  2.11it/s]\n",
      "100%|██████████| 420/420 [03:17<00:00,  2.12it/s]\n",
      "100%|██████████| 525/525 [01:36<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 0.4082 | Val AUC: 0.8540 | Val AP: 0.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [03:18<00:00,  2.12it/s]\n",
      "100%|██████████| 420/420 [03:35<00:00,  1.95it/s]\n",
      "100%|██████████| 420/420 [03:41<00:00,  1.90it/s]\n",
      "100%|██████████| 420/420 [02:55<00:00,  2.39it/s]\n",
      "100%|██████████| 420/420 [02:31<00:00,  2.77it/s]\n",
      "100%|██████████| 525/525 [01:18<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.3743 | Val AUC: 0.8722 | Val AP: 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [02:31<00:00,  2.78it/s]\n",
      "100%|██████████| 420/420 [02:33<00:00,  2.74it/s]\n",
      "100%|██████████| 420/420 [02:32<00:00,  2.75it/s]\n",
      "100%|██████████| 420/420 [02:34<00:00,  2.72it/s]\n",
      "100%|██████████| 420/420 [02:31<00:00,  2.78it/s]\n",
      "100%|██████████| 525/525 [01:17<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Loss: 0.3481 | Val AUC: 0.8749 | Val AP: 0.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [02:30<00:00,  2.79it/s]\n",
      "100%|██████████| 420/420 [02:29<00:00,  2.80it/s]\n",
      "100%|██████████| 420/420 [02:32<00:00,  2.76it/s]\n",
      "100%|██████████| 420/420 [02:40<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):#30 epochen\n",
    "    loss = train()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        val_auc, val_ap = test(val_loader)\n",
    "        print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [01:37<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Loss: 0.3299 | Val AUC: 0.8807 | Val AP: 0.8026\n"
     ]
    }
   ],
   "source": [
    "val_auc, val_ap = test(val_loader)\n",
    "print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [01:40<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val AUC: 0.8723 | Val AP: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t_auc, t_ap = test(test_loader)\n",
    "print(f' Val AUC: {t_auc:.4f} | Val AP: {t_ap:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val AUC: 0.8724 | Val AP: 0.7822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (movie_lin): Linear(in_features=8751, out_features=64, bias=True)\n",
       "  (user_emb): Embedding(47074, 64)\n",
       "  (movie_emb): Embedding(98417, 64)\n",
       "  (gnn): GraphModule(\n",
       "    (conv1): ModuleDict(\n",
       "      (user__review__isbn): SAGEConv(64, 64, aggr=mean)\n",
       "      (isbn__rev_review__user): SAGEConv(64, 64, aggr=mean)\n",
       "    )\n",
       "    (conv2): ModuleDict(\n",
       "      (user__review__isbn): SAGEConv(64, 64, aggr=mean)\n",
       "      (isbn__rev_review__user): SAGEConv(64, 64, aggr=mean)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(hidden_channels=64)\n",
    "model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
